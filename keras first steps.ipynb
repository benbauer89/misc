{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. \n",
    "You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. \n",
    "You can find the dataset in a pandas dataframe called df. \n",
    "For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. \n",
    "The target, wage_per_hour, is available as a NumPy matrix called target.\n",
    "\n",
    "For all exercises in this chapter, we've imported the Sequential model constructor, the Dense layer constructor, and pandas.\n",
    "\n",
    "\n",
    "###########\n",
    "Instructions\n",
    "\n",
    "\n",
    "    Store the number of columns in the predictors data to n_cols. This has been done for you.\n",
    "    Start by creating a Sequential model called model.\n",
    "    Use the .add() method on model to add a Dense layer.\n",
    "    Add 50 units, specify activation='relu', and the input_shape parameter to be the tuple (n_cols,) \n",
    "    which means it has n_cols items in each row of data, and any number of rows of data are acceptable as inputs.\n",
    "    Add another Dense layer. This should have 32 units and a 'relu' activation.\n",
    "    Finally, add an output layer, which is a Dense layer with a single node. Don't use any activation function here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify architecure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2) # number of epochs can go without improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "### df = pd.read_csv(...)\n",
    "\n",
    "# target= df.target_variable\n",
    "\n",
    "# predictors = df.drop(['target_variable'], axis = 1).as_matrix()\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "########## in case of binary calssification:\n",
    "\n",
    "# Add the output layer\n",
    "##model_2.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error') \n",
    "# categorical_crossentropy || logloss for classification\n",
    "# metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.fit(predictors, target) # , validation_split = 0.3, epochs = 20, callbacks = [early_stopping_monitor] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defintion of target variable \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "target = to_categorical(data.target_variable)\n",
    "\n",
    "target_variable  target\n",
    "0               ---> 1 0\n",
    "0               ---> 1 0\n",
    "1               ---> 0 1\n",
    "0               ---> 1 0\n",
    "\n",
    "before compile step \n",
    "model.add(Dense(2, activation='sofmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving, reloading and using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.model import load_model\n",
    "\n",
    "model.save('model_file.h5')\n",
    "\n",
    "my_model = load_model('model_file.h5')\n",
    "\n",
    "predictions = my_model.predict(data_to_predict_with)\n",
    "\n",
    "probability_true = predictions[:,1]\n",
    "\n",
    "# check model\n",
    "\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "plt.plot(model_training.history['val_loss'], 'r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, validation_split=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
